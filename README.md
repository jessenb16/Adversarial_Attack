# Adversarial Attack on ResNet-34 – Project 3

## Overview

This repository contains the code, data, and report for Project 3 of the Deep Learning course, in which we implement and analyze adversarial attacks on a ResNet-34 model trained on ImageNet-1K. We generate adversarial examples using FGSM, PGD, and localized patch attacks, evaluate their impact on ResNet-34, and investigate transferability to DenseNet-121.

## Directory Structure

```
├── project3.ipynb                # Jupyter Notebook with all code and experiments
├── Adversarial Image Examples/   # Folder containing sample adversarial images and Top-5 plots
│   ├── FGSM.png                  # FGSM adversarial example and Top-5 confidences
│   ├── PGD.png                   # PGD adversarial example and Top-5 confidences
│   ├── Patch.png                 # Untargeted patch adversarial example and Top-5 confidences
│   └── Patch_Targeted.png        # Targeted patch adversarial example and Top-5 confidences
└── Deep_Learning_Project_3.pdf   # Final report in AAAI camera-ready format
```

## Requirements

* Python 3.8+
* PyTorch 1.12+
* TorchVision 0.13+
* NumPy 1.20+
* Pillow 8.0+
* tqdm 4.60+
* Matplotlib 3.3+

Install dependencies via:

```bash
pip install torch torchvision numpy pillow tqdm matplotlib
```

## Usage

1. **Prepare the dataset**
   Download the 500-image test set (organized in `ImageFolder` layout) along with `labels_list.json` and place them in the working directory.

2. **Run the notebook**
   Open `project3.ipynb` in Jupyter or Google Colab.  Ensure GPU is enabled for faster computation.

3. **Execute cells**

   * Load and preprocess data.
   * Evaluate baseline Top-1 and Top-5 accuracy on ResNet-34.
   * Generate FGSM, PGD, and patch adversarial sets and save to disk.
   * Evaluate transferability on DenseNet-121.
   * Visualize example failures and compute new accuracy metrics.

4. **View examples**
   The `Adversarial Image Examples/` folder contains representative images for each attack and their Top-5 confidence bar charts.

5. **Read the report**
   See `Deep_Learning_Project_3.pdf` for detailed methodology, analysis and results.

## Results

* **ResNet-34 Baseline:** Top-1 89.6%, Top-5 99.4%
* **FGSM (ε=0.02):** Top-1 \~20.6%, Top-5 \~47.2%
* **PGD (ε=0.02, α=0.005, T=100):** Top-1 \~0.2%, Top-5 \~2.0%
* **PGD-Patch Untargeted (ε=0.50, α=0.06, T=200):** Top-1 \~34.6%, Top-5 \~70.6%
* **PGD-Patch Targeted (ε=0.50, α=0.06, T=200):** Top-1 \~11.8%, Top-5 \~86.6%
* **DenseNet-121 Transferability:** See final_results.png for full numbers.

## Acknowledgements

* Assignment specification: Deep Learning Course (CS6923), NYU 2025
* Pretrained models provided by TorchVision

---

*Generated by the project team – Jesse Noppe-Brandon & Weijun Huang*
